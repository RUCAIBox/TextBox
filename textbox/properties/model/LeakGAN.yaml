generator_lr: 0.001
discriminator_lr: 0.00005
train_batch_size: 128
eval_batch_size: 128
generator_embedding_size: 32
discriminator_embedding_size: 64
hidden_size: 32
dropout_rate: 0.25
l2_reg_lambda: 0.2
filter_sizes: [ 2, 3 ]
filter_nums: [ 100, 200 ]
Monte_Carlo_num: 4
step_size: 4
goal_size: 16
temperature: 1.5
g_pretraining_epochs: 80
d_pretraining_epochs: 80
iter_num: 10
adversarail_training_epochs: 10
adversarail_d_epochs: 15
adversarail_g_epochs: 1
